# Paint-A-Hike üé® üèîÔ∏è
![paintahike+(1)+(1) (1)](https://github.com/user-attachments/assets/379f16a7-5e55-4095-a72a-eaa18d50af3f)

## What It Does
Our web app finds your dream outdoor scenery in the real world. After you make a rough sketch of your ideal location, our web app makes your imagination come to life and gives you the perfect location to visit. It's a perfect app for people who love nature and hiking, along with photographers who are looking for specific scenery to capture. With a simple, intuitive UI and easy user access, it's the perfect way to find whatever scenery you dreamt of.

<img width="1516" height="986" alt="paint-a-hike3" src="https://github.com/user-attachments/assets/74f13758-26e1-49d6-992b-6e5cbab08a5a" />
<h1 align="center">‚Üì</h1>
<img width="1516" height="986" alt="paintresult" src="https://github.com/user-attachments/assets/04e8de70-4f89-4cec-a811-b4467678f157" />

## How We Built It
First, we sketched out various ideas for how we wanted to implement the app and what features to include. After mocking up a design in Figma, we developed the frontend with Next.js, TypeScript, and TailwindCSS, implementing parallax and framer-motion animations to make the UI feel more dynamic. We wanted to lean into the spirit of letting your imagination and creativity run wild, so we used a more playful, hand-drawn design concept for the landing and painting page. The final results page was created with a more modern design to show the transition from fun imaginative drawings into stunning real-world pictures and places. But the real magic shines through in the backend.

In the backend, a Segformer model is run for every single image in our dataset to generate asemantic segmentation map. Essentially, each distinct area of an image is labeled with something like "mountains", "lakes", "flowers", etc. We then compare this to the user's sketch, which is already color coded, corresponding to the same segmentation labels generated by the Segformer. We then rank similarity by calculating the Intersection Over Union (IOU) between the user's sketch and the database images. We also generate CLiP embeddings for each image in our dataset and have Gemini tag the user's sketch with keywords and spatial relationships such as "lake below a mountain". CLiP embedding is then generated for Gemini's tag and compared to the image's CLiP embeddings in addition to the IOU score.

## Challenges We Ran Into
It was difficult to train the machine to be able to identify images and places that matched what the user drew. We had to fine-tune many things, experiment with different drawings, and adjust our model in order to ensure accuracy.

At first, we tried to directly use the vector models of the images users drew and compare them with our dataset, but since the user and dataset images were too different, the same hikes came out every single time. We then tried to upscale the user drawings by using another model to transform them into realistic drawings, but that still was too different from the dataset.

We finally used a segmentation model to isolate different elements of the images such as grass, mountains, water, etc, and by comparing the element map of both image sets, we were able to semi-accurately compare the images.

However, we found the most accurate way to compare images was by also using Gemini to write a description of the user's drawing style and using that text prompt along with the element map to match it to the dataset images, and that gave us the most accurate results.

We also ran into the challenge of figuring out how to connect the frontend and backend along with being able to deploy the entire working web app, but we found that using ngrok to host our backend works just fine.

## What's Next
First, the easy steps. We want to include a loading screen between the painting and the hike reveal, something to show how we're taking your imaginative and making it reality. We also want to develop our app further and make it into a full-fledged product that include locations everywhere in the world and more elements that the AI can recognize, such as snow.

Additionally, we hope to integrate CesiumJS/Cesium Ion to include 3d models of the locations that the users will explore, along with a way to model the path of the trail itself. Adding a user login portal/system so that users can save whatever hikes or drawings they want is also something we're considering adding.

## How To Run It For Yourself

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

## The Three Goats Who Built It
<img width="823" height="465" alt="Screenshot 2025-10-18 at 11 08 03‚ÄØPM" src="https://github.com/user-attachments/assets/46e74fb2-1b64-431d-9cf6-8dcde817cc00" />
